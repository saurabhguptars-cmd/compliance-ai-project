{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOyd2ZY25MhVkvfsHUVR7HG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saurabhguptars-cmd/compliance-ai-project/blob/main/DocumentProcessorv2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "c1VJlxLDme6R",
        "outputId": "24fc048c-91e2-4fe8-e3bb-409cbe1d6f1a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'DocumentProcessor.ipynb'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2012423767.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnotebook_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"DocumentProcessor.ipynb\"\u001b[0m  \u001b[0;31m# Change if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotebook_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnbformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'DocumentProcessor.ipynb'"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# Legal Document Processor â€” Sample Clauses (Safe)\n",
        "# =========================\n",
        "\n",
        "# Install dependencies\n",
        "import sys\n",
        "!{sys.executable} -m pip install -q transformers sentence-transformers torch\n",
        "\n",
        "# Imports\n",
        "from transformers import pipeline\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch, os, pandas as pd, numpy as np\n",
        "\n",
        "# Create folders\n",
        "os.makedirs('data/processed', exist_ok=True)\n",
        "\n",
        "print(\"Torch version:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "\n",
        "# =========================\n",
        "# Step 1: Sample legal clauses\n",
        "# =========================\n",
        "texts = [\n",
        "    \"All customer data must be stored within the European Union.\",\n",
        "    \"Employees must comply with the company's cybersecurity policy.\",\n",
        "    \"Third-party vendors must sign a data protection agreement.\",\n",
        "    \"All financial transactions must be logged and auditable.\",\n",
        "    \"Access to sensitive data must be restricted to authorized personnel.\"\n",
        "]\n",
        "\n",
        "print(\"Extracted\", len(texts), \"clauses\")\n",
        "print(\"Sample clause:\\n\", texts[0])\n",
        "\n",
        "# =========================\n",
        "# Step 2: Generate embeddings\n",
        "# =========================\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "corpus_embeddings = embedder.encode(texts, convert_to_tensor=True, show_progress_bar=True)\n",
        "\n",
        "# Save embeddings & clauses\n",
        "pd.DataFrame({\"clause\": texts}).to_csv(\"data/processed/clauses_sample.csv\", index=False)\n",
        "np.save(\"data/processed/corpus_embeddings.npy\", corpus_embeddings.cpu().numpy())\n",
        "print(\"Embeddings saved!\")\n",
        "\n",
        "# =========================\n",
        "# Step 3: Semantic search\n",
        "# =========================\n",
        "query = \"data residency EU storage location\"\n",
        "query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
        "hits = util.semantic_search(query_embedding, corpus_embeddings, top_k=3)\n",
        "\n",
        "print(\"Top matching clauses:\\n\")\n",
        "for h in hits[0]:\n",
        "    print(\"Score:\", h[\"score\"])\n",
        "    print(\"Clause:\\n\", texts[h[\"corpus_id\"]])\n",
        "    print(\"\\n---\\n\")\n",
        "\n",
        "# =========================\n",
        "# Step 4: Summarization & Simplification\n",
        "# =========================\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\", device=device)\n",
        "simplifier = pipeline(\"text2text-generation\", model=\"google/flan-t5-small\", device=device)\n",
        "\n",
        "sample_text = texts[hits[0][0]['corpus_id']]\n",
        "\n",
        "summary = summarizer(sample_text, max_length=120, min_length=30, do_sample=False)[0]['summary_text']\n",
        "prompt = \"Simplify the following legal clause into 3-4 clear action items for a system analyst:\\n\\n\" + sample_text\n",
        "items = simplifier(prompt, max_length=200)[0]['generated_text']\n",
        "\n",
        "print(\"Summary:\\n\", summary)\n",
        "print(\"\\nAction Items:\\n\", items)\n",
        "\n",
        "# =========================\n",
        "# Step 5: Save outputs\n",
        "# =========================\n",
        "with open(\"data/processed/sample_clause.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(sample_text)\n",
        "with open(\"data/processed/sample_summary.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(summary)\n",
        "with open(\"data/processed/sample_items.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(items)\n",
        "\n",
        "print(\"Saved outputs in data/processed/\")\n"
      ]
    }
  ]
}